\section{Introduction}
\label{s:intro}
%Replicated services (or replicated state machines, \RSM{s}) must communicate with each other, yet cannot do so efficiently today. 
%This paper describes a practical and general-purpose method for efficiently communicating between RSMs, with constant overhead in the absence of failures, and bounded message resends under failures. 
%\nc{Upon reading it, im not sure we need this paragraph? WHat do others think?}\mk{I tend to agree. Also, the last sentence seems too specific.}

Many organizations today use replicated state machines to provide high performance and reliability for applications ranging from key-value stores to microservices. Notable companies like Uber~\cite{uber-engg-microservice,uber-micro-macro} and Doordash~\cite{doordash-microservice-failure} build their infrastructure around replication, using more than $1000$ microservices that must communicate~\cite{aegean}. State-machine replication ensures that each such service is consistent and available: a replicated state machine (\RSM{}) offers to clients the appealing abstraction of a never-failing service, even as the underlying machines on which it runs may crash or act maliciously. Similarly, conversations with government agencies reveal that, for security, services cannot be managed across agency borders. 
Instead, any shared information must be \textit{communicated} across \RSM{s}.  
Breaking down monolithic \RSM{s} into sub-\RSM{s} can also be beneficial for performance:  GeoBFT~\cite{geobft,blockchain-book}, for instance, 
highlights the benefit of running sub-\RSM{s} "locally", minimizing geo-distributed communication. 

%Most organizations with an eye towards performance and organizational scaling adopt a microservice-style architecture. 
%The availability and integrity of each such service is ensured through state-machine replication: 

These examples speak of a common need: RSMs must support the ability to efficiently and reliably exchange messages with other RSMs (whether they implement the same consensus protocol internally or not). Unfortunately, there is currently no formal or practical way for two RSMs to communicate. 
Existing solutions are either ad-hoc, offer vague (and evolving) guarantees~\cite{blockchain-interop-survey}, 
rely on a trusted third-party~\cite{trustboost}), or 
require an expensive all-to-all broadcast~\cite{spanner,sharper}. The most closely related work, Aegean~\cite{aegean}, acknowledges that RSMs must communicate, but targets a different problem: nested requests in which an RSM must make an internal request to a different service while processing the first request. 

In this paper, we propose a new primitive, the \CCCFull{} (\CCC{}) that can be used by two arbitrary RSMs to communicate. \CCC{} generalizes Reliable Broadcast to guarantee that, if RSM $A$ sends $m$, at least one correct replica in RSM $B$ should receive $m$. Any implementation of the \CCC{} primitive should offer the following properties:  1) \textit{robustness under failures}:  actively malicious or crashed nodes should neither affect correctness nor cause system throughput to drop.
2) \textit{low-overhead in the common-case}: for efficiency, a \CCC{} protocol should send only a constant amount of additional metadata in the failure-free case. 
3) \textit{generality}: arbitrary RSMs with heterogeneous sizes, communication, and fault models should be able to communicate. It should, for instance, be possible to link a Byzantine Fault-Tolerant (\BFT)  protocol with a Crash-Fault-Tolerant (CFT) algorithm. Similarly, asynchronous and partially synchronous protocols should also be able to communicate effectively.


We then introduce \Scrooge{}, a practical \CCC{} protocol that allows for arbitrary \RSM{s} with heterogeneous communication and failure models to efficiently communicate. The key to \Scrooge{}'s good performance lies in observing that the C3B problem and the goals of TCP~\cite{computer-networks-book} share similarities. TCP seeks to offer reliable, ordered delivery between two hosts in a way that dynamically reacts to congestion and anomalies in the network. To do so at low cost, it leverages full-duplex communication and cumulative acknowledgements (ACKs) to asynchronously detect when messages have been received. Conversely, repeated ACKs of the same message reveal message loss. \Scrooge{} takes inspiration from these techniques, and modifies them to account for the differences between C3B and TCP: 
1) Unlike TCP, which is exclusively designed for point-to-point messaging, \Scrooge{} must handle many-to-many communication and 
disseminate knowledge of failed/successful message deliveries across many nodes, 
2) \Scrooge{} must ensure that no Byzantine participant will violate correctness or cause excessive re-transmissions. In contrast, TCP does not consider malicious failures. No TCP node will falsely claim to have sent or received a message.


% \Scrooge{} adopts a similar approach, but must deal with two additional challenges. First, TCP cannot handle many-to-many communication; it is exclusively designed for point-to-point messaging. Second, TCP nodes fail only by crashing. No protocol participant will falsely claim to have sent or received a message. 
% In contrast, \Scrooge{}
% must ensure that no Byzantine participant can violate correctness
% or cause excessive retransmissions.
 
 To this effect, \Scrooge{} introduces the notion of \quack{}s. A \quack{} is a cumulative quorum acknowledgement for a message $m$. It concisely summarizes that all messages up to $m$ have been reliably received by at least an honest node;
\textit{repeated} \quack{}s for $m$ instead indicate that the next message in the sequence was not received at the receiving RSM. \
\Scrooge{} uses \textit{apportionment}~\cite{apportionment} to fairly rotate individual sender-receiver pairs in a way that ensures all nodes in each RSM quickly and efficiently learn which messages have been reliably received at the receiving RSM.

Using \quack{}s in \Scrooge{} yields multiple benefits. First, it ensures \textit{generality}. It allows for \Scrooge{} to seamlessly work for crash fault tolerant systems as well as for both traditional and stake-based byzantine fault tolerant protocols. The protocol makes no synchrony or partial synchrony assumption. Second, \Scrooge{}'s \quack{}-driven implementation has low-overhead. In the failure-free case, \Scrooge{} sends each message only once, and requires only two additional counters per-message. Finally, when failures do arise, \Scrooge{} remains \textit{robust} as its resend strategy minimizes the number of messages resent: no Byzantine node can unilaterally cause spurious message retransmissions.


%Naturally, our system has some limitations. 
%In the worst-case,  \Scrooge{} may resend messages up to $2\f{}+1$ times ($\f{}$ denotes the maximum number of nodes that can fail in an \RSM{}) 
%as the first $2\f{}$ attempts may fail since a Byzantine sender or Byzantine receiver may intentionally drop the message. 
%This is a fundamental limitation of all \CCC{} protocols. We show, however, that after only constant resends, there is already a $99.99999\%$ probability that the message has been successfully delivered. 
%Importantly, this result holds independently of network size or the value of $\f{}$. 
%The performance of \Scrooge{} under failures is thus w.h.p independent of $\f{}$.
%
Our results confirm \Scrooge{}'s strong guarantees. 
\Scrooge{} allows disparate protocols such as \pbft~\cite{pbftj}, Raft~\cite{raft} and Algorand~\cite{algorand} to communicate. When consensus is not the bottleneck, \Scrooge{} achieves $3.2\times$ better performance than a traditional All-to-All broadcast for small networks, and up to $24\times$ for large networks.

In summary, this paper makes the following contributions:
\begin{enumerate}
    \item We introduce and formalize the \CCCFull{} primitive, that allows for two RSMs to communicate.
    \item We present \Scrooge{}, a practical \CCC{} protocol. Key to \Scrooge's good performance is the use of \quack{s} (cumulative quorum acknowledgments), which precisely determine when messages have definitely been
    received, or definitely been lost.
    \item We make use of the mathematics of apportionment to ensure that the performance of \Scrooge{} is preserved in the presence of stake-based RSMs with arbitrary variations of stake
%    \item \nc{I dislike putting eval and implementation as a a contribution, but Manos would like to}\mk{The idea is that in a systems paper the performance results are part of the story and a contribution in and of themselves.}\nc{Sure, but you almost always conclude with the performance numbers - I tend to dislike it as its a contribution that says "we did our job"}
\end{enumerate}

%
%\begin{itemize}
%\item \nc{I always finds it easiest to start with a header "This paper describes the first efficient and general RSM-to-RSM communication protocol. Then you describe the context (it helps give people an idea of what you're going to talk about whe you start the background}
%There are ample scenarios where two or more organizations may 
%need to communicate with each other:
%(1) Alice may ask Robinhood to transfer all her assets to Fidelity. 
%(2) Bob may request conversion of his Ether to Algos.
%(3) Two shards need to exchange data to fulfill a cross-shard transaction.
%\item As all of these organizations need to store and exchange some data, 
%they must employ at least one Replicated State Machine (\RSM{}) to 
%reliably manage this data.
%\nc{I'd first start with why you want a  (BFT) RSM and then introduce the desire for communicate : Organisations ensure the availability and integrity of mission-critical services through replication; through \textit{state machine replication} (RSM), they offer clients the abstraction of a single correct machine in the presence of failures. More recently, increased concerns about trust and machine compromise has led companies to offer \textit{byzantine fault-tolerant} (BFT) RSM, which are guaranteed to remain correct in the presence of arbitrary machine failures. Modern services often consist of multiple RSMS, be it for organisational or performance reasons. (Organisational) Large companies often adopt a micro-service style architecture: Uber's infrastructure consists for more than 1000 microservices. Conversations with government agencies reveal that, for security, RSMs cannot cross agency boarders, yet their systems must frequently interact. In the specific context of blockchain systems, users may want to convert Ethers to Algos. (Performance) Developers may choose to break down an RSM into multiple sub-RSMs for performance reasons: GeoBFT highlighted the benefit of running sub-RSMS "locally", minimizing geo-distributed communication. Similarly, sub-RSMs are often used as shards in a system for scalability. Supporting cross-shard transactions requires them to periodically communicate.  
%In short, BFT RSMs must support the ability to efficiently and reliability exchange messages with other RSMs.}
%\item Another common denominator in all of the aforementioned scenarios 
%is a {\em communication fabric}
%that facilitates data exchange between two organizations.
%If the communicating organizations trust each other and no failures can occur, 
%the communication problem is trivially solved.
%Unfortunately, failures are common, organizations may act maliciously, 
%and trust is often fleeting.
%\nc{It's good practice to not start a paragraph with "another point is ..", you always want to make sure that there's a directed "flow" from one paragraph to the next, suggesting that there's "another ..." means that you probably should have started the previous paragraph by "there are two issues ... " etc.}
%\nc{I'm not sure I understood the point of this paragraph?} 
%
%\item Unfortunately, existing literature lacks a concrete primitive 
%that expresses reliable communication between two organizations, and 
%includes {\em ad hoc} solutions to resolve this problem. 
%\nc{I'd say: There is currently no formal or practical way for two RSMs to communicate. Existing solutions offer vague (and evolving) guarantees~\cite{}, rely on a trusted third-party~\cite{}, or require an expensive all-to-all broadcast}
%
%\item To this end, this paper first lays down the 
%\CCCFull{} (\CCC{}) primitive. 
%Unlike reliable broadcast, which defines communication between two nodes, 
%\CCC{} expresses communication between two \RSM{s} and
%defines the necessary safety and liveness properties, 
%such as validity, no duplication, integrity and consistency.
%\nc{In this paper, we initiate the formal and practical study of the 
%\CCCFull{} problem. \CCC{} generalises Reliable Broadcast to enforce
%safety and liveness guarantees between two RSMs.}
%
%\item Next, we present our novel \Scrooge{} protocol, which correctly
%implements the \CCC{} primitive.
%\Scrooge{} is the first distributed and trustless cross-cluster 
%communication protocol, which guards against 
%malicious attacks and in the good case broadcasts {\em zero} copies of 
%each message.
%\nc{Usually, you want the system to be after the challenges, so I would move this bullet down and say "An efficient and practical \CCC{} protocol should offer the following guarantees: 1) generality
%(support arbtirary RSMs + no third-party) 2) low-overhead in the common-case (minimal additional messages sent) 3) robustness under failures}
%
%\item Prior to designing \Scrooge{}, we had to solve three key challenges
%impacting existing solutions:
%\begin{enumerate}[wide,nosep]
%\item {\em Heterogenity.}
%Two communicating \RSM{s} may differ from each other on a variety of parameters:
%(i) They could have different number of replicas, 
%(ii) They may have different failure models: crash failures vs. malicious failures.
%(iii) They could run different protocols for fault-tolerant replication. 
%(iv) They may assign different weights to different replicas to indicate priority.
%\nc{I'd move this bullet to be what you talk about in Requirement 1 above. I'd also be more precise, when you talk about weights, talk about proof of stake more directly. When you're talking about the requirements for a protocol, remember that you are talking about high level features, not Scrooge specifically: For example, we shouldn't talk about acks as there could exist a protocol implements C3PO but doesn't use acks}
%
%\item {\em Resiliency.}
%The communication fabric guaranteeing message delivery between the \RSM{s} should 
%satisfy the following properties:
%(i) It should not depend on a {\em trusted third-party}.
%(ii) It should not depend on a {\em trusted} programmable code. 
%{iii} It should continue operation despite some failures. 
%{iv} It should ensure operation under asynchrony.
%\nc{I'd move asynchrony under generality. To me, generality has two axis: composing arbitary fault-models and arbitrary communication models. Composing arbitrary communication models requires any C3PO protocol to be asynchronous. Composing arbitrary failure models requires C3PO to  ...}
%
%\item {\em Efficiency.}
%The communication fabric guaranteeing message delivery between the \RSM{s} should 
%satisfy the following:
%(i) It should be scalable.
%(ii) It should communicate {\em zero} copies of each message until failures.
%(iii) It should minimize the number of message acknowledgments. 
%(iv) It should be able to take advantage of full-duplex data flow.
%\end{enumerate}
%
%\item Unfortunately, existing solutions at most resolve one of these three challenges.
%On the one hand, solutions relying on trusted third-party or program are unsecure as 
%the trusted entity can be compromised, sink of targeted attacks, 
%or source for DOS attacks.
%Further, these solutions are extremely compute-intensive and have high latencies.
%
%\item On the other hand, existing trustless solutions create massive copies 
%of each message and expect a synchronous network.
%For example: an {\em all-to-all} protocol, 
%where all replicas in one \RSM{} send a copy of each message to all the 
%replicas in other \RSM{}, creates a total of $O(n^2)$ copies.
%Optimized variants of this protocol run expensive recovery mechanisms under failures.
%
%\nc{I agree with you that this is the right place to be a bit more detailed about existing solutions, but I would split it in "Existing solutions all fall-short. In the blockchain setting, ... In the RSM setting, all-to-all + this is the place to mention Adam as people will think of Adam and we want to make sure its clear early that it targets a different problem}
%
%\item \nc{In this work,  propose Scrooge, the first C3PO protocol that satisfies all the aforementioned requirements. You want to highlight here what are the properties that Scrooge satisfies (before going into details about Scrooge). Scrooge is asynchronous, supports RSMs of arbitrary size in the CFT, BFT model, traditional BFT + proof of stake. In the common case, sends no additional messages. In the failure case, sends at most X additional messages}
%
%Our protocol \Scrooge{} meets all the challenges.
%\Scrooge's replicas determine whether a message has been 
%delivered or not through our novel
%{\em quorum acknowledgments} (\quack{}).
%These \quack{s} assure the sender that the desired message has
%been delivered to at least one non-faulty receiver.
%As at most $\f{}$ replicas of the receiver \RSM{} can fail, a 
%\quack{} is composed of $\f{}+1$ acknowledgments.
%\nc{You are going into a lot of detail very quickly, and describing particular implementation details.  In an SOSP paper, you want to make sure to describe the key idea first. The key idea here is not quacks, that's an "example" of a technique that follows the  philosophy of the key idea. To me, (but we should discuss this), is
%that we "asynchronously" build a snapshot of what has been sent/received. We observe that what we're doing is, in effect, a reliable communication stream a la TCP, except that we are doing multiple nodes to multiple nodes communication, and that nodes can lie. The core tenants of TCP communication is to succintly summarise the state of the network + leveraging full duplex. We find that we can actually adopt much of the same techniques ...  }
%
%\item In the case of streaming applications, which require a
%continuous flow of messages, our \quack{s} can overwhelm the network. 
%As a result, our \quack{s} are {\em cumulative} in nature; 
%one acknowledgement message announces delivery of several consecutive messages.
%Moreover, unlike large messages, these acknowledgments have a small 
%constant size.
%
%\item Finally, \Scrooge{} supports full-duplex communication 
%where both the \RSM{s} can communicate messages at the same time.
%In fact, full duplex communication helps to hide the costs of 
%cumulative \quack{s} as the receiver can piggyback an acknowledgment 
%with an outgoing message.
%\nc{See comments above}
%
%
%\item \nc{I'd be great to talk about Reggie's optimisation here, with the 99.999\%, I think this is a very nice and interesting result that we should make sure we implement and put in the intro} To reiterate our claim that \Scrooge{} facilitates a high 
%performance communication among two \RSM{s}, in Figure~\ref{f:intro}, 
%we compare it against three state-of-the-art solutions: 
%(1) zk-bridge, a trusted, smart-contract bridge,
%(2) all-to-all communication protocol, and
%(3) one-to-one pairing protocol.
%The zk-bridge facilitates asset movement between two crypto-currencies
%Ethereum to Tendermint; we selected zk-bridge as it is the only 
%smart-contract bridge that has not been hacked.
%Trusteless protocols including \Scrooge{} facilitate 
%communication between two \RSM{s} running \pbft{} consensus.
%In this experiment, all the messages communicated across the \RSM{s} are \SI{1}{Mib} in size.
%For our measurements, we only take into account the latency of 
%communicating the message, and discard any costs or benefits of different
%consensus protocols.
%\nc{I'd recommending mirroring the text of past papers to introduce the evaluation section, there's usually a pretty "standard" way of doing so}
%
%
%
%
%
%\end{itemize}
%A large number of existing applications require communication between multiple clusters of replicas. 
%Examples of such applications include: 
%(i) Sharded systems where cross-shard transactions need to access data from two or more independent shards.
%(ii) Geo-replicated systems where the data is replicated across clusters, which are spread across the globe;
%these clusters need to periodically exchange data to ensure consistency.
%(iii) Two or more \Name{SMR}s running distinct consensus protocols; recent cross-chain blockchain applications
%target connecting two different blockchains and permit exchange of different crypto-tokens.
%
%Each of these applications can be viewed as a collection of independent clusters where each cluster manages its 
%own data and needs data from other clusters.
%Assume that each cluster has $\n{}$ machines.
%A naive way to exchange a message (say $m$) between two clusters is to require every machine in the sending cluster to send the
%message $m$ to every machine in the receiving cluster. 
%But, such a communication policy will result in transmitting $\n{}^2$ copies of the message $m$.
%To optimize this, a recent work shows that it is sufficient to transmit only $\n{}$ copies of the message $m$ 
%to guarantee that every machine of the receiving cluster {\em eventually} receives the message.
%Although this solution is linear in the number of machines in a cluster, 
%its use in streaming applications is still prohibitive as these applications have to continuously transmit 
%messages and this solution requires sending $\n{}$ copies per message, which will easily bottleneck the network.
%
%To resolve these challenges, in this work, we present the design of a communication protocol that 
%in the best case requires only sending {\em one} copy per message. 
%We call our protocol as {\em Shadow} as we target it for applications where clusters participate in 
%bi-directional communication (each cluster will act as a sender for some message and a receiver for another) and 
%irrespective of their nature (sender or receiver), the protocol remains the same.
%



